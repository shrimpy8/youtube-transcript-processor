{"success":true,"summaries":[{"provider":"anthropic","modelName":"Anthropic Sonnet 4.5","summary":"### Opening\n\nIn this episode, Zevy Arnowitz—a product manager at Meta with zero technical background—reveals how he went from being terrified of code to shipping production-ready features using AI tools like Cursor and Claude. The conversation centers on a practical, repeatable workflow that non-technical PMs can adopt to build real products, not just prototypes. Zevy's approach transforms AI from a novelty into a structured system for ideation, planning, execution, and review—all without writing a single line of code by hand.\n\n### Key Ideas\n\nZevy's journey began with a revelation in Japan when Sonnet 3.5 launched. Watching creators build apps with tools like Bolt and Lovable felt like someone handed him superpowers. He started with those no-code platforms, but as his side project Studymate—a quiz app for students—grew more complex, he hit their limits. Payments integration and database migrations exposed the trade-off: beginner-friendly tools are opinionated and limit control. Zevy graduated to Cursor, where Claude Code runs directly in his codebase, giving him full decision-making power while still leveraging AI's speed.\n\nThe heart of Zevy's workflow is a series of custom slash commands in Cursor—reusable prompts that guide Claude through each stage of development. It starts with `/create-issue`, which captures feature ideas mid-flow and logs them in Linear without breaking focus. When he's ready to build, `/exploration-phase` kicks off a conversation where Claude analyzes the codebase, asks clarifying questions, and surfaces technical considerations Zevy might miss. This isn't about getting instant answers—it's about exposing the right questions. Next, `/create-plan` generates a structured markdown document outlining tasks, critical decisions, and implementation steps. This plan becomes a reference for both Zevy and the AI, ensuring alignment before any code is written.\n\nExecution comes next with `/execute-plan`, where Cursor's Composer model—blazingly fast, as Zevy describes it—writes the code in minutes. But speed alone isn't enough. The real challenge for non-technical PMs is reviewing AI-generated code. Zevy's solution is ingenious: he runs `/review` to have Claude critique its own work, then opens CodeX (ChatGPT's coding tool) and Gemini in parallel to get second and third opinions. Each model has distinct strengths—Claude is communicative and opinionated, CodeX is the silent genius who fixes gnarly bugs, and Gemini excels at UI but takes chaotic routes to get there. Zevy then uses `/peer-review` to feed these external critiques back to Claude, framing it as a dev lead defending its decisions. This multi-model review catches mistakes Zevy couldn't spot himself and builds his understanding over time.\n\nDocumentation updates close the loop. Whenever Claude makes a mistake, Zevy asks it to reflect on the root cause and update its tooling or system prompts so the error doesn't recur. This post-mortem habit—borrowed from traditional product work—turns failures into learning opportunities. Over time, the system gets smarter, and so does Zevy. He emphasized that this isn't about outsourcing thinking; it's about harnessing AI as a collaborative partner. He compared it to working with a CTO who's always available, never judges, and helps you level up—but you still own the output.\n\n### Practical Takeaways\n\nFor PMs ready to adopt this workflow, Zevy recommends starting slow. Begin with a ChatGPT project configured as a technical co-founder, using custom instructions to make it opinionated and collaborative rather than sycophantic. This exposure therapy helps you get comfortable with technical concepts before diving into Cursor's intimidating interface. Once you're ready, download Zevy's slash commands and plug them into Cursor. The `/create-issue`, `/exploration-phase`, and `/create-plan` sequence structures your thinking before any code is written—critical for avoiding the chaos of \"vibe coding\" without a plan.\n\nWhen reviewing AI-generated code, don't rely on a single model. Run reviews in Cursor, CodeX, and Gemini simultaneously, then use `/peer-review` to reconcile their feedback. This triangulation catches edge cases and builds your intuition for what good code looks like. Zevy also stressed the `/learning-opportunity` command: whenever something confuses you, invoke it to get a tailored explanation at your level. This transforms building into a learning experience, not just a shortcut.\n\nFinally, treat your AI workflow like a product. Conduct post-mortems after every feature. Ask Claude what in its prompts or documentation led to mistakes, then update those resources. Over time, your system becomes more reliable, and you become more capable. Zevy's advice for PMs at larger companies was measured: don't ship database migrations solo, but contained UI projects or prototypes are fair game—especially if you create a pull request for an engineer to review. The key is making your codebase AI-native with clear documentation and structure, a task that requires technical buy-in.\n\n### Closing Thought\n\nZevy's story challenges the assumption that non-technical PMs must stay in their lane. By treating AI as a thought partner rather than a magic button, he's built a profitable side business, shipped features at Meta, and developed a technical intuition that would have taken years to acquire through traditional means. The tools are accessible, the workflow is replicable, and the opportunity is enormous. As Zevy put it: it's not that AI will replace you—it's that someone better at using AI will. The question isn't whether to start building; it's whether you'll open your laptop today and begin.","success":true}]}